{
  "metadata": {
    "kernelspec": {
      "display_name": "Python37 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "lastEditStatus": {
      "notebookId": "gen3ngeceatab4eblilz",
      "authorId": "8790037420708",
      "authorName": "AFERAS",
      "authorEmail": "allie.feras@snowflake.com",
      "sessionId": "a51e2acc-a656-4ad9-bf8e-08286dc4bc4c",
      "lastEditTime": 1762526341927
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e79ae8e5-aec2-4276-9443-074c3a614142",
      "metadata": {
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "# ‚ùÑÔ∏è End-to-end ML Demo ‚ùÑÔ∏è\n\nIn this worfklow we will work through the following elements of a typical tabular machine learning pipeline.\n\n### 1. Use Feature Store to track engineered features\n* Store feature defintions in feature store for reproducible computation of ML features\n      \n### 2. Train two Models using the Snowflake ML APIs\n* Baseline XGboost\n* XGboost with optimal hyper-parameters identified via Snowflake ML distributed HPO methods\n\n### 3. Register both models in Snowflake model registry\n* Explore model registry capabilities such as **metadata tracking, inference, and explainability**\n* Compare model metrics on train/test set to identify any issues of model performance or overfitting\n* Tag the best performing model version as 'default' version\n### 4. Set up Model Monitor to track 1 year of predicted and actual loan repayments\n* **Compute performance metrics** such a F1, Precision, Recall\n* **Inspect model drift** (i.e. how much has the average predicted repayment rate changed day-to-day)\n* **Compare models** side-by-side to understand which model should be used in production\n* Identify and understand **data issues**\n\n### 5. Track data and model lineage throughout\n* View and understand\n  * The **origin of the data** used for computed features\n  * The **data used** for model training\n  * The **available model versions** being monitored"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2512cb5-15ae-40b2-84c7-8a44a9979670",
      "metadata": {
        "language": "python",
        "collapsed": true,
        "codeCollapsed": true
      },
      "outputs": [],
      "source": "!pip install snowflake-ml-python==1.18.0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d78265b8-8baa-4136-a32a-32f3f620949d",
      "metadata": {
        "codeCollapsed": false,
        "collapsed": false,
        "language": "python"
      },
      "outputs": [],
      "source": "#Update this VERSION_NUM to version your features, models etc!\nVERSION_NUM = '0'\nDB = \"E2E_SNOW_MLOPS_DB\" \nSCHEMA = \"MLOPS_SCHEMA\" \nCOMPUTE_WAREHOUSE = \"E2E_SNOW_MLOPS_WH\" \nROLE = \"E2E_SNOW_MLOPS_ROLE\""
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ce110000-1111-2222-3333-ffffff000000",
      "metadata": {
        "codeCollapsed": false,
        "collapsed": false,
        "language": "python",
        "resultHeight": 84
      },
      "outputs": [],
      "source": "import pandas as pd\nimport numpy as np\nimport sklearn\nimport math\nimport pickle\nimport shap\nfrom datetime import datetime\nfrom xgboost import XGBClassifier\n\nfrom versioning import version_featureview, version_data\n\n# Snowpark ML\nfrom snowflake.ml.registry import Registry\nfrom snowflake.ml.modeling.tune import get_tuner_context\nfrom snowflake.ml.modeling import tune\nfrom entities import search_algorithm\n\n#Snowflake feature store\nfrom snowflake.ml.feature_store import FeatureStore, FeatureView, Entity, CreationMode\n\n# Snowpark session\nfrom snowflake.snowpark import DataFrame\nimport snowflake.snowpark.functions as F\nfrom snowflake.snowpark.functions import col, to_timestamp, min, max, month, dayofweek, dayofyear, avg, date_add, sql_expr\nfrom snowflake.snowpark.types import IntegerType, StringType\nfrom snowflake.snowpark import Window\n\n#setup snowpark session\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\n# session.use_role('')\nsession.use_role(ROLE)\nsession.use_warehouse(COMPUTE_WAREHOUSE)\nsession.use_database(DB)\nsession.use_schema(SCHEMA)\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8900d1d-a1f2-419b-ae7e-b194f268d904",
      "metadata": {
        "codeCollapsed": false,
        "collapsed": false,
        "language": "python",
        "resultHeight": 223
      },
      "outputs": [],
      "source": "df = session.table(\"MORTGAGE_LENDING_DEMO_DATA\")\ndf.show(5)"
    },
    {
      "cell_type": "markdown",
      "id": "60938b6f-bda7-4783-ae44-547bd34d98de",
      "metadata": {
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "## Observe Snowflake Snowpark table properties"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6654de7-6407-4ffe-a214-fd66078397ef",
      "metadata": {
        "codeCollapsed": false,
        "collapsed": false,
        "language": "python",
        "resultHeight": 111
      },
      "outputs": [],
      "source": "df.select(min('TS'), max('TS')).show()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b5a38cc-c479-4839-b0ae-9e5cb3e0facb",
      "metadata": {
        "codeCollapsed": false,
        "language": "python"
      },
      "outputs": [],
      "source": "#Get current date and time\ncurrent_time = datetime.now()\ndf_max_time = datetime.strptime(str(df.select(max(\"TS\")).collect()[0][0]), \"%Y-%m-%d %H:%M:%S.%f\")\n\n#Find delta between latest existing timestamp and today's date\ntimedelta = current_time- df_max_time"
    },
    {
      "cell_type": "markdown",
      "id": "8aa46c7d-519b-422c-8932-9b031fc6b4bd",
      "metadata": {
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "## Feature Engineering with Snowpark APIs"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b355c0c4-9dc6-4faf-86b7-24d8d559e453",
      "metadata": {
        "codeCollapsed": false,
        "collapsed": false,
        "language": "python",
        "resultHeight": 0
      },
      "outputs": [],
      "source": "#Create a dict with keys for feature names and values containing transform code\n\nfeature_eng_dict = dict()\n\n#Timstamp features\nfeature_eng_dict[\"TIMESTAMP\"] = date_add(to_timestamp(\"TS\"), timedelta.days-1)\nfeature_eng_dict[\"MONTH\"] = month(\"TIMESTAMP\")\nfeature_eng_dict[\"DAY_OF_YEAR\"] = dayofyear(\"TIMESTAMP\") \nfeature_eng_dict[\"DOTW\"] = dayofweek(\"TIMESTAMP\")\n\n# df= df.with_columns(feature_eng_dict.keys(), feature_eng_dict.values())\n\n#Income and loan features\nfeature_eng_dict[\"LOAN_AMOUNT\"] = col(\"LOAN_AMOUNT_000s\")*1000\nfeature_eng_dict[\"INCOME\"] = (col(\"APPLICANT_INCOME_000s\")*1000).astype(IntegerType())\nfeature_eng_dict[\"INCOME_LOAN_RATIO\"] = col(\"INCOME\")/col(\"LOAN_AMOUNT\")\n\ndf_eng = df.with_columns(feature_eng_dict.keys(), feature_eng_dict.values())\ndf_eng.show(3)"
    },
    {
      "id": "397181b6-b573-46fb-bb9e-cad30d7b82d0",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "# Create county/year level income data\navg_income = df_eng.with_column(\"TIMESTAMP\",F.date_trunc(\"YEAR\",\"TIMESTAMP\")).group_by(\"COUNTY_NAME\",\"TIMESTAMP\").agg(F.mean(\"INCOME\").alias(\"YEAR_AVG_INCOME\"))\navg_income.show()",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "6878a590-8462-4718-9dc1-5a2cde3d2d75",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "# create one hot encoded features\n\ncat_cols = [\"LOAN_PURPOSE_NAME\"]\n\nohe_dict = {}\nfor c in cat_cols:\n    vals = df_eng.select(c).distinct().collect()\n\n    for v in vals:\n        key = f\"{c}_{v[c].replace(' ','_').upper()}\"\n        ohe_dict[key] = (col(c)==v[c]).astype(IntegerType())\n        \nohe_df = df_eng.with_columns(ohe_dict.keys(), ohe_dict.values())\n\nohe_df = ohe_df.select([\"LOAN_ID\",\"TIMESTAMP\"]+list(ohe_dict.keys()))\nohe_df.show()",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "72d7645e-e0ac-4539-b132-54ce53431402",
      "metadata": {
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "## Create a Snowflake Feature Store"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abacdc71-9f2c-419f-8d50-3e8f89be367f",
      "metadata": {
        "codeCollapsed": false,
        "collapsed": false,
        "language": "python",
        "resultHeight": 0
      },
      "outputs": [],
      "source": "fs = FeatureStore(\n    session=session, \n    database=DB, \n    name=SCHEMA, \n    default_warehouse=COMPUTE_WAREHOUSE,\n    creation_mode=CreationMode.CREATE_IF_NOT_EXIST\n)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67480d6a-183f-4373-aaa8-d3ed8e80e11d",
      "metadata": {
        "codeCollapsed": false,
        "collapsed": false,
        "language": "python",
        "resultHeight": 111
      },
      "outputs": [],
      "source": "fs.list_entities()"
    },
    {
      "cell_type": "markdown",
      "id": "d915406f-e52d-4baf-9f6c-b9e0e8d53e6e",
      "metadata": {
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "## Feature Store configuration\n- create/register entities of interest"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e91d6d39-7819-4825-8729-a3f19ca5cdf7",
      "metadata": {
        "codeCollapsed": false,
        "collapsed": false,
        "language": "python",
        "resultHeight": 38
      },
      "outputs": [],
      "source": "#First try to retrieve an existing entity definition, if not define a new one and register\ntry:\n    #retrieve existing entity\n    loan_id_entity = fs.get_entity('LOAN_ENTITY') \n    print('Retrieved existing entity')\nexcept:\n#define new entity\n    loan_id_entity = Entity(\n        name = \"LOAN_ENTITY\",\n        join_keys = [\"LOAN_ID\"],\n        desc = \"Features defined on a per loan level\")\n    #register\n    fs.register_entity(loan_id_entity)\n    print(\"Registered new entity\")"
    },
    {
      "cell_type": "markdown",
      "id": "5cf84fe3-4120-4092-b43d-8873da57d461",
      "metadata": {
        "collapsed": false,
        "codeCollapsed": false
      },
      "source": "\nWe can define the dataframe via the use of Snowpark APIs, and use that dataframe (or a function that returns a dataframe) as the feature view definition, below."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b53364f-90c4-45b4-94ee-b2fde6f93475",
      "metadata": {
        "codeCollapsed": false,
        "collapsed": false,
        "language": "python",
        "resultHeight": 0
      },
      "outputs": [],
      "source": "#Create a dataframe with just the ID, timestamp, and engineered features. We will use this to define our feature view\nfeature_df = df_eng.select([\"LOAN_ID\"]+list(feature_eng_dict.keys()))\nfeature_df.show(5)\n\n#define and register feature view\nloan_fv = FeatureView(\n    name=\"Mortgage_Feature_View\",\n    entities=[loan_id_entity],\n    feature_df=feature_df,\n    timestamp_col=\"TIMESTAMP\",\n    refresh_freq=\"1 day\")\n\n#add feature level descriptions\n\nloan_fv = loan_fv.attach_feature_desc(\n    {\n        \"MONTH\": \"Month of loan\",\n        \"DAY_OF_YEAR\": \"Day of calendar year of loan\",\n        \"DOTW\": \"Day of the week of loan\",\n        \"LOAN_AMOUNT\": \"Loan amount in $USD\",\n        \"INCOME\": \"Household income in $USD\",\n        \"INCOME_LOAN_RATIO\": \"Ratio of LOAN_AMOUNT/INCOME\",\n    }\n)\n\nloan_fv = fs.register_feature_view(loan_fv, version=VERSION_NUM,overwrite=True)\n\n# alternatively, use version hashing\n#version = version_featureview(loan_fv)\n#loan_fv = fs.register_feature_view(loan_fv, version=version)"
    },
    {
      "cell_type": "code",
      "id": "b67e2395-fbd7-4eb9-9318-62699038f4b2",
      "metadata": {
        "language": "python",
        "codeCollapsed": false
      },
      "outputs": [],
      "source": "#define and register feature view for one hot ended categories\ncat_fv = FeatureView(\n    name=\"Mortgage_Feature_View_CATEGORIES\",\n    entities=[loan_id_entity],\n    feature_df=ohe_df,\n    timestamp_col=\"TIMESTAMP\",\n)\n\ncat_fv = fs.register_feature_view(cat_fv, version=VERSION_NUM,overwrite=True)\n\n# alternatively, use version hashing\n#version = version_featureview(cat_fv)\n#cat_fv = fs.register_feature_view(cat_fv, version=version)",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "cdb13563-98fa-4f54-9b87-4a9f0643e829",
      "metadata": {
        "language": "python",
        "codeCollapsed": false
      },
      "outputs": [],
      "source": "#First try to retrieve an existing entity definition, if not define a new one and register\ntry:\n    #retrieve existing entity\n    year_entity = fs.get_entity('COUNTY') \n    print('Retrieved existing entity')\nexcept:\n#define new entity\n    year_entity = Entity(\n        name = \"COUNTY\",\n        join_keys = [\"COUNTY_NAME\"],\n        desc = \"Features defined on a county level\")\n    #register\n    fs.register_entity(year_entity)\n    print(\"Registered new entity\")",
      "execution_count": null
    },
    {
      "id": "deea6e4e-a811-455b-a608-6b6a343da22e",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "#define and register feature view\nyear_fv = FeatureView(\n    name=\"Mortgage_Feature_View_Years\",\n    entities=[year_entity],\n    feature_df=avg_income,\n    timestamp_col=\"TIMESTAMP\",\n)\n\nyear_fv = fs.register_feature_view(year_fv, version=VERSION_NUM,overwrite=True)\n\n# alternatively, use version hashing\n#version = version_featureview(cat_fv)\n#cat_fv = fs.register_feature_view(cat_fv, version=version)",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "e96ff67f-bb04-40cb-8c14-11b5ebb2917d",
      "metadata": {
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "## Retrieve a Dataset from the featureview\n\nSnowflake Datasets are immutable, file-based objects that exist within your Snowpark session. \n\nThey can be written to persistent Snowflake objects as needed. "
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "535efc80-e4fc-41c5-98eb-5b5450bcf199",
      "metadata": {
        "codeCollapsed": false,
        "collapsed": false,
        "language": "python",
        "resultHeight": 0
      },
      "outputs": [],
      "source": "# subset of data, only need the features used to fetch rest of feature view\nspine_df = df_eng.select(\"LOAN_ID\", \"TIMESTAMP\", \"MORTGAGERESPONSE\", \"COUNTY_NAME\").filter(month(\"TIMESTAMP\")==10)\n\n# automatically join (time aware) all 3 feature views\nds = fs.generate_dataset(\n    name=f\"MORTGAGE_DATASET_EXTENDED_FEATURES\",\n    spine_df=spine_df, \n    features=[loan_fv, cat_fv, year_fv],\n    spine_timestamp_col=\"TIMESTAMP\",\n    spine_label_cols=[\"MORTGAGERESPONSE\"]\n)"
    },
    {
      "id": "32ee2e62-5590-475d-a3bc-e8eb52605c5a",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "# split data\n\nds_sp = ds.read.to_snowpark_dataframe()\n\ntrain, test = ds_sp.random_split(weights=[0.70, 0.30], seed=0)",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "e5cbffe1-df0a-45f8-83eb-361db5e6dc0d",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "#Define model config\nxgb_base = XGBClassifier(\n    max_depth=50,\n    n_estimators=3,\n    learning_rate = 0.75,\n    booster = 'gbtree')\n\n#Split train data into X, y\ntrain_pd = train.to_pandas()\nX_train_pd = train_pd.drop([\"TIMESTAMP\", \"LOAN_ID\", \"MORTGAGERESPONSE\",\"COUNTY_NAME\"],axis=1) #remove\ny_train_pd = train_pd.MORTGAGERESPONSE\n\n#train model\nxgb_base.fit(X_train_pd,y_train_pd)\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "d151cbc3-6e13-49ff-8adb-0e9b266cb7d5",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "#Create a snowflake model registry object \nfrom snowflake.ml.registry import Registry\n\n# Define model name\nmodel_name = f\"MORTGAGE_LENDING_MLOPS_{VERSION_NUM}\"\n\n# Create a registry to log the model to\nmodel_registry = Registry(session=session, \n                          database_name=DB, \n                          schema_name=SCHEMA,\n                          options={\"enable_monitoring\": True})",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "3a160a65-b6d0-485a-960a-936133ce6ca2",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "#Log the base model to the model registry (if not already there)\nbase_version_name = 'XGB_BASE'\n\ntry:\n    #Check for existing model\n    mv_base = model_registry.get_model(model_name).version(base_version_name)\n    print(\"Found existing model version!\")\nexcept:\n    print(\"Logging new model version...\")\n    #Log model to registry\n    mv_base = model_registry.log_model(\n        model_name=model_name,\n        model=xgb_base, \n        version_name=base_version_name,\n        sample_input_data = train.drop([\"TIMESTAMP\", \"LOAN_ID\", \"MORTGAGERESPONSE\",\"COUNTY_NAME\"]).limit(100), #using snowpark df to maintain lineage\n        comment = f\"\"\"ML model for predicting loan approval likelihood.\n                    This model was trained using XGBoost classifier.\n                    Hyperparameters used were:\n                    max_depth={xgb_base.max_depth}, \n                    n_estimators={xgb_base.n_estimators}, \n                    learning_rate = {xgb_base.learning_rate}, \n                    algorithm = {xgb_base.booster}\n                    \"\"\",\n        target_platforms= [\"WAREHOUSE\", \"SNOWPARK_CONTAINER_SERVICES\"],\n        options= {\"enable_explainability\": True}\n\n    )\n    \n    #set metrics\n    mv_base.set_metric(metric_name=\"Train_F1_Score\", value=f1_base_train)\n    mv_base.set_metric(metric_name=\"Train_Precision_Score\", value=precision_base_train)\n    mv_base.set_metric(metric_name=\"Train_Recall_score\", value=recall_base_train)",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "e17071ca-0f50-4277-9305-6aebc93e9334",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "reg_preds = mv_base.run(test, function_name = \"predict\").rename(col('\"output_feature_0\"'), \"MORTGAGE_PREDICTION\")\nreg_preds.show(10)",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "25b85666-8f01-43ee-8a8b-2c4f5893c1eb",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "train.write.save_as_table(f\"DEMO_MORTGAGE_LENDING_TRAIN_{VERSION_NUM}\", mode=\"overwrite\")\ntest.write.save_as_table(f\"DEMO_MORTGAGE_LENDING_TEST_{VERSION_NUM}\", mode=\"overwrite\")\n\nsession.sql(\"CREATE stage IF NOT EXISTS ML_STAGE\").collect()\n\nfrom snowflake import snowpark\n\ndef demo_inference_sproc(session: snowpark.Session, table_name: str, modelname: str, modelversion: str) -> str:\n\n    reg = Registry(session=session)\n    m = reg.get_model(model_name)  # Fetch the model using the registry\n    mv = m.version(modelversion)\n    \n    input_table_name=table_name\n    pred_col = f'{modelversion}_PREDICTION'\n\n    # Read the input table to a dataframe\n    df = session.table(input_table_name)\n    results = mv.run(df, function_name=\"predict\").select(\"LOAN_ID\",'\"output_feature_0\"').withColumnRenamed('\"output_feature_0\"', pred_col)\n    # 'results' is the output DataFrame with predictions\n\n    final = df.join(results, on=\"LOAN_ID\", how=\"full\")\n    # Write results back to Snowflake table\n    final.write.save_as_table(table_name, mode='overwrite',enable_schema_evolution=True)\n\n    return \"Success\"\n\n# Register the stored procedure\nsession.sproc.register(\n    func=demo_inference_sproc,\n    name=\"model_inference_sproc\",\n    replace=True,\n    is_permanent=True,\n    stage_location=\"@ML_STAGE\",\n    packages=['joblib', 'snowflake-snowpark-python', 'snowflake-ml-python'],\n    return_type=StringType()\n)",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "a97787f4-f50f-4587-a2c2-d1703b723f8a",
      "cell_type": "code",
      "metadata": {
        "language": "sql",
        "resultVariableName": "dataframe_1"
      },
      "source": "CALL model_inference_sproc('DEMO_MORTGAGE_LENDING_TRAIN_{{VERSION_NUM}}','{{model_name}}', '{{base_version_name}}');\nCALL model_inference_sproc('DEMO_MORTGAGE_LENDING_TEST_{{VERSION_NUM}}','{{model_name}}', '{{base_version_name}}');",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "7fe5b237-d6ad-4552-8311-ddda11fa1e1d",
      "cell_type": "code",
      "metadata": {
        "resultVariableName": "dataframe_2",
        "language": "sql"
      },
      "source": "CREATE OR REPLACE MODEL MONITOR MORTGAGE_LENDING_BASE_MODEL_MONITOR\nWITH\n    MODEL={{model_name}}\n    VERSION={{base_version_name}}\n    FUNCTION=predict\n    SOURCE=DEMO_MORTGAGE_LENDING_TEST_{{VERSION_NUM}}\n    BASELINE=DEMO_MORTGAGE_LENDING_TRAIN_{{VERSION_NUM}}\n    TIMESTAMP_COLUMN=TIMESTAMP\n    PREDICTION_CLASS_COLUMNS=(XGB_BASE_PREDICTION)  \n    ACTUAL_CLASS_COLUMNS=(MORTGAGERESPONSE)\n    ID_COLUMNS=(LOAN_ID)\n    WAREHOUSE={{COMPUTE_WAREHOUSE}}\n    REFRESH_INTERVAL='12 hours'\n    AGGREGATION_WINDOW='1 day';",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "ce110000-1111-2222-3333-ffffff000036",
      "metadata": {
        "collapsed": false,
        "jp-MarkdownHeadingCollapsed": true,
        "resultHeight": 202,
        "tags": [],
        "codeCollapsed": true
      },
      "source": "## Conclusion \n\n#### üõ†Ô∏è Snowflake Feature Store tracks feature definitions and maintains lineage of sources and destinations üõ†Ô∏è\n#### üöÄ Snowflake Model Registry gives users a secure and flexible framework to log models, tag candidates for production, and run inference and explainability jobs üöÄ\n#### üìà ML observability in Snowflake allows users to montior model performance over time and detect model, feature, and concept drift üìà\n#### üîÆ All models logged in the Model Registry can be accessed for inference, explainability, lineage tracking, visibility and more üîÆ"
    }
  ]
}