{
 "metadata": {
  "kernelspec": {
   "display_name": "Python37 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "lastEditStatus": {
   "notebookId": "4mku4lpnhsw3o42lssor",
   "authorId": "8790037420708",
   "authorName": "AFERAS",
   "authorEmail": "allie.feras@snowflake.com",
   "sessionId": "85679e77-08e8-4730-b679-bb35e7ca58fe",
   "lastEditTime": 1757012256195
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e79ae8e5-aec2-4276-9443-074c3a614142",
   "metadata": {
    "name": "INTRO_MD",
    "collapsed": false
   },
   "source": "# ❄️ End-to-end ML Demo ❄️\n\nIn this worfklow we will work through the following elements of a typical tabular machine learning pipeline.\n\n### 1. Use Feature Store to track engineered features\n* Store feature defintions in feature store for reproducible computation of ML features\n      \n### 2. Train two Models using the Snowflake ML APIs\n* Baseline XGboost\n* XGboost with optimal hyper-parameters identified via Snowflake ML distributed HPO methods\n\n### 3. Register both models in Snowflake model registry\n* Explore model registry capabilities such as **metadata tracking, inference, and explainability**\n* Compare model metrics on train/test set to identify any issues of model performance or overfitting\n* Tag the best performing model version as 'default' version\n### 4. Set up Model Monitor to track 1 year of predicted and actual loan repayments\n* **Compute performance metrics** such a F1, Precision, Recall\n* **Inspect model drift** (i.e. how much has the average predicted repayment rate changed day-to-day)\n* **Compare models** side-by-side to understand which model should be used in production\n* Identify and understand **data issues**\n\n### 5. Track data and model lineage throughout\n* View and understand\n  * The **origin of the data** used for computed features\n  * The **data used** for model training\n  * The **available model versions** being monitored"
  },
  {
   "cell_type": "code",
   "id": "a2512cb5-15ae-40b2-84c7-8a44a9979670",
   "metadata": {
    "language": "python",
    "name": "pip_installs",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "!pip install shap snowflake-ml-python==1.11.0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d78265b8-8baa-4136-a32a-32f3f620949d",
   "metadata": {
    "language": "python",
    "name": "set_version_num_and_vars",
    "codeCollapsed": false,
    "collapsed": false
   },
   "outputs": [],
   "source": "DB = \"E2E_SNOW_MLOPS_DB\" \nSCHEMA = \"MLOPS_SCHEMA\" \nCOMPUTE_WAREHOUSE = \"E2E_SNOW_MLOPS_WH\"\nROLE = \"E2E_SNOW_MLOPS_ROLE\"",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "name": "imports_and_session",
    "language": "python",
    "collapsed": false,
    "resultHeight": 84,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "import pandas as pd\nimport numpy as np\nimport sklearn\nimport math\nimport pickle\nimport shap\nfrom datetime import datetime\nimport streamlit as st\nfrom xgboost import XGBClassifier\nfrom version import version_featureview, version_data, version_model\n\n# Snowpark ML\nfrom snowflake.ml.registry import Registry\nfrom snowflake.ml.modeling.tune import get_tuner_context\nfrom snowflake.ml.modeling import tune\nfrom snowflake.ml.dataset import Dataset\nfrom entities import search_algorithm\n\n#Snowflake feature store\nfrom snowflake.ml.feature_store import FeatureStore, FeatureView, Entity, CreationMode\n\n# Snowpark session\nfrom snowflake.snowpark import DataFrame\nfrom snowflake.snowpark.functions import col, upper, replace, to_timestamp, min, max, month, dayofweek, dayofyear, avg, date_add, sql_expr\nfrom snowflake.snowpark.types import IntegerType\nfrom snowflake.snowpark import Window\n\n#setup snowpark session\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\nsession.use_role(ROLE)\n\nsession",
   "id": "ce110000-1111-2222-3333-ffffff000000"
  },
  {
   "cell_type": "code",
   "id": "f8900d1d-a1f2-419b-ae7e-b194f268d904",
   "metadata": {
    "language": "python",
    "name": "read_raw_data",
    "resultHeight": 223,
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "try:\n    print(\"Reading table data...\")\n    df = session.table(\"MORTGAGE_LENDING_DEMO_DATA\")\n    df.show(5)\nexcept:\n    print(\"Table not found! Uploading data to snowflake table\")\n    df_pandas = pd.read_csv(\"MORTGAGE_LENDING_DEMO_DATA.csv.zip\")\n    session.write_pandas(df_pandas, \"MORTGAGE_LENDING_DEMO_DATA\", auto_create_table=True)\n    df = session.table(\"MORTGAGE_LENDING_DEMO_DATA\")\n    df.show(5)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "60938b6f-bda7-4783-ae44-547bd34d98de",
   "metadata": {
    "name": "md1",
    "collapsed": false
   },
   "source": "## Observe Snowflake Snowpark table properties"
  },
  {
   "cell_type": "code",
   "id": "a6654de7-6407-4ffe-a214-fd66078397ef",
   "metadata": {
    "language": "python",
    "name": "see_timespan",
    "collapsed": false,
    "resultHeight": 111,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "df.select(min('TS'), max('TS'))",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4b5a38cc-c479-4839-b0ae-9e5cb3e0facb",
   "metadata": {
    "language": "python",
    "name": "find_timedelta",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "#Get current date and time\ncurrent_time = datetime.now()\ndf_max_time = datetime.strptime(str(df.select(max(\"TS\")).collect()[0][0]), \"%Y-%m-%d %H:%M:%S.%f\")\n\n#Find delta between latest existing timestamp and today's date\ntimedelta = current_time- df_max_time\n\n#Update timestamps to represent last ~1 year from today's date\ndf.select(min(date_add(to_timestamp(\"TS\"), timedelta.days-1)), max(date_add(to_timestamp(\"TS\"), timedelta.days-1)))",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8aa46c7d-519b-422c-8932-9b031fc6b4bd",
   "metadata": {
    "name": "feat_eng_md",
    "collapsed": false
   },
   "source": "## Feature Engineering with Snowpark APIs"
  },
  {
   "cell_type": "code",
   "id": "b355c0c4-9dc6-4faf-86b7-24d8d559e453",
   "metadata": {
    "language": "python",
    "name": "define_features",
    "resultHeight": 0,
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "#Create a dict with keys for feature names and values containing transform code\n\nfeature_eng_dict = dict()\n\n#Timstamp features\nfeature_eng_dict[\"TIMESTAMP\"] = date_add(to_timestamp(\"TS\"), timedelta.days-1)\nfeature_eng_dict[\"MONTH\"] = month(\"TIMESTAMP\")\nfeature_eng_dict[\"DAY_OF_YEAR\"] = dayofyear(\"TIMESTAMP\") \nfeature_eng_dict[\"DOTW\"] = dayofweek(\"TIMESTAMP\")\n\n# df= df.with_columns(feature_eng_dict.keys(), feature_eng_dict.values())\n\n#Income and loan features\nfeature_eng_dict[\"LOAN_AMOUNT\"] = col(\"LOAN_AMOUNT_000s\")*1000\nfeature_eng_dict[\"INCOME\"] = col(\"APPLICANT_INCOME_000s\")*1000\nfeature_eng_dict[\"INCOME_LOAN_RATIO\"] = col(\"INCOME\")/col(\"LOAN_AMOUNT\")\n\ncounty_window_spec = Window.partition_by(\"COUNTY_NAME\")\nfeature_eng_dict[\"MEAN_COUNTY_INCOME\"] = avg(\"INCOME\").over(county_window_spec)\nfeature_eng_dict[\"HIGH_INCOME_FLAG\"] = (col(\"INCOME\")>col(\"MEAN_COUNTY_INCOME\")).astype(IntegerType())\n\nfeature_eng_dict[\"AVG_THIRTY_DAY_LOAN_AMOUNT\"] =  sql_expr(\"\"\"AVG(LOAN_AMOUNT) OVER (PARTITION BY COUNTY_NAME ORDER BY TIMESTAMP  \n                                                            RANGE BETWEEN INTERVAL '30 DAYS' PRECEDING AND CURRENT ROW)\"\"\")\n\nfeature_eng_dict['LOAN_PURPOSE_NAME'] = upper(replace(col(\"LOAN_PURPOSE_NAME\"),\" \",\"_\"))\ndf = df.with_columns(feature_eng_dict.keys(), feature_eng_dict.values())\ndf.show(3)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b6c4ead8-25ac-46cc-9bd9-17eac2f796d5",
   "metadata": {
    "language": "python",
    "name": "df_explain",
    "resultHeight": 312,
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "df.explain()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "72d7645e-e0ac-4539-b132-54ce53431402",
   "metadata": {
    "name": "feature_store_markdown",
    "collapsed": false
   },
   "source": "## Create a Snowflake Feature Store"
  },
  {
   "cell_type": "code",
   "id": "abacdc71-9f2c-419f-8d50-3e8f89be367f",
   "metadata": {
    "language": "python",
    "name": "define_feature_store",
    "collapsed": false,
    "resultHeight": 0,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "fs = FeatureStore(\n    session=session, \n    database=DB, \n    name=SCHEMA, \n    default_warehouse=COMPUTE_WAREHOUSE,\n    creation_mode=CreationMode.CREATE_IF_NOT_EXIST\n)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "67480d6a-183f-4373-aaa8-d3ed8e80e11d",
   "metadata": {
    "language": "python",
    "name": "list_entities",
    "resultHeight": 111,
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "fs.list_entities()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d915406f-e52d-4baf-9f6c-b9e0e8d53e6e",
   "metadata": {
    "name": "FS_CONFIG_MD",
    "collapsed": false
   },
   "source": "## Feature Store configuration\n- create/register entities of interest"
  },
  {
   "cell_type": "code",
   "id": "e91d6d39-7819-4825-8729-a3f19ca5cdf7",
   "metadata": {
    "language": "python",
    "name": "load_or_register_entity",
    "resultHeight": 38,
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "#First try to retrieve an existing entity definition, if not define a new one and register\ntry:\n    #retrieve existing entity\n    loan_id_entity = fs.get_entity('LOAN_ENTITY') \n    print('Retrieved existing entity')\nexcept:\n#define new entity\n    loan_id_entity = Entity(\n        name = \"LOAN_ENTITY\",\n        join_keys = [\"LOAN_ID\"],\n        desc = \"Features defined on a per loan level\")\n    #register\n    fs.register_entity(loan_id_entity)\n    print(\"Registered new entity\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2820463f-0ea7-43ea-a500-9b034011887d",
   "metadata": {
    "language": "python",
    "name": "create_feature_df",
    "resultHeight": 217,
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "#Create a dataframe with just the ID, timestamp, and engineered features. We will use this to define our feature view\nfeature_df = df.select([\"LOAN_ID\"]+list(feature_eng_dict.keys()))\nfeature_df.show(5)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ee4d7732-22d0-4830-b6fd-ef94b03e913f",
   "metadata": {
    "name": "FS_MD",
    "collapsed": false
   },
   "source": "Here, the feature store references an existing table. \n\nWe could also define the dataframe via the use of Snowpark APIs, and use that dataframe (or a function that returns a dataframe) as the feature view definition, below."
  },
  {
   "cell_type": "code",
   "id": "2b53364f-90c4-45b4-94ee-b2fde6f93475",
   "metadata": {
    "language": "python",
    "name": "feature_veiw_creation",
    "collapsed": false,
    "resultHeight": 0,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "#define and register feature view\nloan_fv = FeatureView(\n    name=\"Mortgage_Feature_View\",\n    entities=[loan_id_entity],\n    feature_df=feature_df,\n    timestamp_col=\"TIMESTAMP\",\n    refresh_freq=\"1 day\")\n\n#add feature level descriptions\n\nloan_fv = loan_fv.attach_feature_desc(\n    {\n        \"MONTH\": \"Month of loan\",\n        \"DAY_OF_YEAR\": \"Day of calendar year of loan\",\n        \"DOTW\": \"Day of the week of loan\",\n        \"LOAN_AMOUNT\": \"Loan amount in $USD\",\n        \"INCOME\": \"Household income in $USD\",\n        \"INCOME_LOAN_RATIO\": \"Ratio of LOAN_AMOUNT/INCOME\",\n        \"MEAN_COUNTY_INCOME\": \"Average household income aggregated at county level\",\n        \"HIGH_INCOME_FLAG\": \"Binary flag to indicate whether household income is higher than MEAN_COUNTY_INCOME\",\n        \"AVG_THIRTY_DAY_LOAN_AMOUNT\": \"Rolling 30 day average of LOAN_AMOUNT\"\n    }\n)\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8f734850-9924-4aaf-aa7d-7f55b1106011",
   "metadata": {
    "name": "feature_view_version_md",
    "collapsed": false
   },
   "source": "### Feature view versioning\n\nThe version_featureview function below takes a feature view and computes the md5 hash of its query and the key/value of given metadata fields. This hash can be used as the version when registering the feature view.\n\nWe are hashing the **definition** of the table, not the data, so data refreshes do not change the version. Changes to the code, however, could change the version.\n\nIf the code is rerun (with or without changes) and table definition does not change, the hash will not change. Registering a feature view with the same version hash will NOT re-initialize the table (unless set to overwrite). This prevents running unnecessary compute.\n\nBy default, the function only includes the query in the feature view definition. Include additional keys that \"matter\" to the versioned definition in the keys argument.\n"
  },
  {
   "cell_type": "code",
   "id": "62be6db7-c154-4596-bc1f-9a8a6c0ad49f",
   "metadata": {
    "language": "python",
    "name": "feature_view_version"
   },
   "outputs": [],
   "source": "fv_version = version_featureview(loan_fv)\nloan_fv = fs.register_feature_view(loan_fv, version=fv_version)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "18c3225b-b936-4aa7-81f2-27bbaeee1c0f",
   "metadata": {
    "language": "python",
    "name": "show_feature_views",
    "resultHeight": 111,
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "fs.list_feature_views()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0f7a1aae-0bd2-4aad-b9ed-3347fc56b6ea",
   "metadata": {
    "language": "python",
    "name": "create_feature_store_link",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "#Create link to feature store UI to inspect newly created feature view!\norg_name = session.sql('SELECT CURRENT_ORGANIZATION_NAME()').collect()[0][0]\naccount_name = session.sql('SELECT CURRENT_ACCOUNT_NAME()').collect()[0][0]\n\nst.write(f'https://app.snowflake.com/{org_name}/{account_name}/#/features/database/{DB}/store/{SCHEMA}')",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e96ff67f-bb04-40cb-8c14-11b5ebb2917d",
   "metadata": {
    "name": "FV_MD",
    "collapsed": false
   },
   "source": "## Retrieve a Dataset from the featureview\n\nSnowflake Datasets are immutable, file-based objects that exist within your Snowpark session. \n\nThey can be written to persistent Snowflake objects as needed. \n\nWe must generate the dataframe and then register it as a dataset object, to allow to data versioning, instead of directly generating the dataset object."
  },
  {
   "cell_type": "code",
   "id": "535efc80-e4fc-41c5-98eb-5b5450bcf199",
   "metadata": {
    "language": "python",
    "name": "generate_data",
    "resultHeight": 0,
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "ds_sp = fs.generate_training_set(\n    spine_df=df.select(\"LOAN_ID\", \"TIMESTAMP\",\"MORTGAGERESPONSE\"), #only need the features used to fetch rest of feature view\n    features=[loan_fv],\n    spine_timestamp_col=\"TIMESTAMP\",\n    spine_label_cols=[\"MORTGAGERESPONSE\"]\n)\n\nds_sp.show()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6a6add70-20f6-4cc6-b89b-22ddeff2498c",
   "metadata": {
    "name": "dataset_version_md",
    "collapsed": false
   },
   "source": "### Dataset versioning\n\nThe version_data function differs from the version_featureview function because it DOES version the data itself. It uses the HASH_AGG function to compute a hash of the data.\n\nIf the code or query used to produce the data changes, but the data itself does not, the version will not be changed. Saving a dataset with the same version will cause an error, so we do need to handle that in any pipelines using this functionality."
  },
  {
   "cell_type": "code",
   "id": "43a2c892-074d-4d7a-a8ee-fdee98bcbc29",
   "metadata": {
    "language": "python",
    "name": "dataset_version",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "ds_version = version_data(ds_sp)\n\ndataset_name = \"MORTGAGE_DATASET_EXTENDED_FEATURES\"\n\ndataset = Dataset.create(session, name=dataset_name, exist_ok=True)\nif ds_version in dataset.list_versions():\n    ds = dataset.select_version(ds_version)\nelse:\n    ds = dataset.create_version(\n        version=ds_version,\n        input_dataframe=ds_sp,\n        label_cols=[\"MORTGAGERESPONSE\"],        \n    )",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "eee5da03-8837-47d9-833f-172019d43498",
   "metadata": {
    "language": "python",
    "name": "train_test_split"
   },
   "outputs": [],
   "source": "train, test = ds_sp.random_split(weights=[0.70, 0.30], seed=0)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ed563321-b82c-4b08-ac93-d223fecd07cb",
   "metadata": {
    "name": "preprocessing_md",
    "collapsed": false
   },
   "source": "### Preprocessing\n\nWe do this preprocessing in sklearn framework to create a ColumnTransformer to use in a Pipeline later on."
  },
  {
   "cell_type": "code",
   "id": "a58f927f-e1de-47fa-b2fc-c442c8cad95e",
   "metadata": {
    "language": "python",
    "name": "to_pandas"
   },
   "outputs": [],
   "source": "train_pd = train.to_pandas()\ntest_pd = test.to_pandas()\n\nX_train_pd = train_pd.drop([\"TIMESTAMP\", \"LOAN_ID\", \"MORTGAGERESPONSE\"],axis=1) #remove\ny_train_pd = train_pd.MORTGAGERESPONSE",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "31f42e25-04a8-42d0-bace-f1ba0d0978f6",
   "metadata": {
    "language": "python",
    "name": "preprocessing",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "from sklearn.preprocessing import OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.compose import ColumnTransformer\n\n\nohe = OneHotEncoder(sparse_output=False).set_output(transform=\"pandas\")\nimpute = SimpleImputer(strategy='constant',fill_value=0).set_output(transform=\"pandas\")\n\ntransformer = ColumnTransformer(\n    [\n        ('ohe', ohe, X_train_pd.select_dtypes(\"object\").columns),\n        ('impute', impute, X_train_pd.select_dtypes(\"number\").columns)\n    ],\n    remainder='passthrough',\n    verbose_feature_names_out=False\n).set_output(transform='pandas')",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "38c05dc9-2efb-4c5f-995a-486ef926c6c5",
   "metadata": {
    "name": "model_training_md",
    "collapsed": false
   },
   "source": "## Model Training\n### Below we will define and fit an xgboost classifier as our baseline model and evaluate the performance\n##### Note this is all done with OSS frameworks"
  },
  {
   "cell_type": "code",
   "id": "5e4b5fba-b7a8-47ff-aaf6-076b9e78dcaf",
   "metadata": {
    "language": "python",
    "name": "define_model",
    "resultHeight": 0,
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "#Define model config\nxgb_base = XGBClassifier(\n    max_depth=50,\n    n_estimators=3,\n    learning_rate = 0.75,\n    booster = 'gbtree')",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d0961a23-e942-4dc4-a388-4e7892a979d6",
   "metadata": {
    "language": "python",
    "name": "create_pipeline",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "from sklearn.pipeline import Pipeline\n\nbase = Pipeline(\n    [\n        ('transform', transformer),\n        ('xgb', xgb_base)\n    ]\n)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "644f3295-2496-4fd0-ae95-922a78c5b944",
   "metadata": {
    "language": "python",
    "name": "train_base_model",
    "resultHeight": 1759,
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "#train model\nbase.fit(X_train_pd,y_train_pd)\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0c5ac861-fcf9-47b2-9c11-ec44ee2367e4",
   "metadata": {
    "language": "python",
    "name": "compute_predictions_and_perf_metrics",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "from sklearn.metrics import f1_score, precision_score, recall_score\ntrain_preds_base = base.predict(X_train_pd) #update this line with correct ata\n\nf1_base_train = round(f1_score(y_train_pd, train_preds_base),4)\nprecision_base_train = round(precision_score(y_train_pd, train_preds_base),4)\nrecall_base_train = round(recall_score(y_train_pd, train_preds_base),4)\n\nprint(f'F1: {f1_base_train} \\nPrecision {precision_base_train} \\nRecall: {recall_base_train}')",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "93777778-d2ba-42d5-88c4-a90ba18c5006",
   "metadata": {
    "name": "model_regisry_md",
    "collapsed": false,
    "resultHeight": 74
   },
   "source": "# Model Registry\n\n- Log models with important metadata\n- Manage model lifecycles\n- Serve models from Snowflake runtimes"
  },
  {
   "cell_type": "code",
   "id": "21678e59-deaf-4c2b-b01e-1c59fe31b10a",
   "metadata": {
    "language": "python",
    "name": "define_model_registry",
    "resultHeight": 0,
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "#Create a snowflake model registry object \nfrom snowflake.ml.registry import Registry\n\n# Define model name\nmodel_name = f\"MORTGAGE_LENDING_MLOPS\"\n\n# Create a registry to log the model to\nmodel_registry = Registry(session=session, \n                          database_name=DB, \n                          schema_name=SCHEMA,\n                          options={\"enable_monitoring\": True})",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1ecc4b4d-15f1-428d-ae7d-2c53300e31c9",
   "metadata": {
    "name": "version_model_md",
    "collapsed": false
   },
   "source": "### Version model\n\nThe model versioning function simply pickles the model object and computes the md5 hash. \"V_\" is added to the front of the version because model registry versions cannot start with a number"
  },
  {
   "cell_type": "code",
   "id": "be41c3ac-49f0-4fd9-a557-9d8eb633f602",
   "metadata": {
    "language": "python",
    "name": "register_model_version",
    "collapsed": false,
    "resultHeight": 229,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "#Log the base model to the model registry (if not already there)\nbase_version_name = version_model(xgb_base)\n\ntry:\n    #Check for existing model\n    mv_base = model_registry.get_model(model_name).version(base_version_name)\n    print(\"Found existing model version!\")\nexcept:\n    print(\"Logging new model version...\")\n    #Log model to registry\n    mv_base = model_registry.log_model(\n        model_name=model_name,\n        model=base, \n        version_name=base_version_name,\n        sample_input_data = train.drop([\"TIMESTAMP\", \"LOAN_ID\", \"MORTGAGERESPONSE\"]).limit(100), #using snowpark df to maintain lineage\n        comment = f\"\"\"ML model for predicting loan approval likelihood.\n                    This model was trained using XGBoost classifier.\n                    Hyperparameters used were:\n                    max_depth={xgb_base.max_depth}, \n                    n_estimators={xgb_base.n_estimators}, \n                    learning_rate = {xgb_base.learning_rate}, \n                    algorithm = {xgb_base.booster}\n                    \"\"\",\n        target_platforms= [\"WAREHOUSE\", \"SNOWPARK_CONTAINER_SERVICES\"],\n        options= {\"enable_explainability\": False},\n    )\n    \n    #set metrics\n    mv_base.set_metric(metric_name=\"Train_F1_Score\", value=f1_base_train)\n    mv_base.set_metric(metric_name=\"Train_Precision_Score\", value=precision_base_train)\n    mv_base.set_metric(metric_name=\"Train_Recall_score\", value=recall_base_train)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "68e2ddab-b02a-4e05-8121-4e97e49e0eea",
   "metadata": {
    "language": "python",
    "name": "create_prod_tag",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "#Create tag for PROD model\nsession.sql(\"CREATE OR REPLACE TAG PROD\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9e0054df-0cd9-4e81-98b8-6564be86b4b9",
   "metadata": {
    "language": "python",
    "name": "create_PROD_tag",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "#Apply prod tag \nm = model_registry.get_model(model_name)\nm.comment = \"Loan approval prediction models\" #set model level comment\nm.set_tag(\"PROD\", base_version_name)\nm.show_tags()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ac4e294e-929d-4399-b2bb-d5d2d1dd043e",
   "metadata": {
    "language": "python",
    "name": "show_models",
    "resultHeight": 111,
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "model_registry.show_models()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e3dfb281-9751-48a1-a76e-43ffffd9d099",
   "metadata": {
    "language": "python",
    "name": "show_model_versions",
    "resultHeight": 146,
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "model_registry.get_model(model_name).show_versions()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "eb1af8a1-7a92-455e-b9a1-8f2c699dfdeb",
   "metadata": {
    "language": "python",
    "name": "print_model_version_and_metrics",
    "resultHeight": 239,
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "print(mv_base)\nprint(mv_base.show_metrics())",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8ecdf05c-b3b5-4755-bdff-fd187ef07f58",
   "metadata": {
    "language": "python",
    "name": "show_model_functions",
    "resultHeight": 2133,
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "mv_base.show_functions()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bf495261-a8a7-46be-b9c8-3f099268d154",
   "metadata": {
    "language": "python",
    "name": "predict_from_registry",
    "resultHeight": 351,
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "preds_pd = mv_base.run(test_pd, function_name = \"predict\").rename(columns={\"output_feature_0\": \"MORTGAGE_PREDICTION\"})\npreds_pd",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9ef61447-10e7-4a38-a429-3da3facf9ce7",
   "metadata": {
    "language": "python",
    "name": "compute_test_metrics",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "f1_base_test = round(f1_score(test_pd.MORTGAGERESPONSE, preds_pd.MORTGAGE_PREDICTION),4)\nprecision_base_test = round(precision_score(test_pd.MORTGAGERESPONSE, preds_pd.MORTGAGE_PREDICTION),4)\nrecall_base_test = round(recall_score(test_pd.MORTGAGERESPONSE, preds_pd.MORTGAGE_PREDICTION),4)\n\n#log metrics to model registry model\nmv_base.set_metric(metric_name=\"Test_F1_Score\", value=f1_base_test)\nmv_base.set_metric(metric_name=\"Test_Precision_Score\", value=precision_base_test)\nmv_base.set_metric(metric_name=\"Test_Recall_score\", value=recall_base_test)\n\nprint(f'F1: {f1_base_test} \\nPrecision {precision_base_test} \\nRecall: {recall_base_test}')",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9b477885-35ce-486d-9e86-7d0cc9d48454",
   "metadata": {
    "name": "HPO_MD",
    "collapsed": false
   },
   "source": "# Oh no! Our model's performance seems to have dropped off significantly from training to our test set. \n## This is evidence that our model is overfit - can we fix this with Distributed Hyperparameter Optimization??"
  },
  {
   "cell_type": "code",
   "id": "c47e068d-7e1d-4c74-8289-d03ea8ab3c7e",
   "metadata": {
    "language": "python",
    "name": "setup_x_and_y",
    "collapsed": false
   },
   "outputs": [],
   "source": "X_train = train.drop(\"MORTGAGERESPONSE\", \"TIMESTAMP\", \"LOAN_ID\")\ny_train = train.select(\"MORTGAGERESPONSE\")\nX_test = test.drop(\"MORTGAGERESPONSE\",\"TIMESTAMP\", \"LOAN_ID\")\ny_test = test.select(\"MORTGAGERESPONSE\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fff76e05-38f5-47cf-ab5d-9eefed09bd71",
   "metadata": {
    "language": "python",
    "name": "define_HPO_config",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "from snowflake.ml.data import DataConnector\nfrom snowflake.ml.modeling.tune import get_tuner_context\nfrom snowflake.ml.modeling import tune\nfrom entities import search_algorithm\nimport psutil\n\n#Define dataset map\ndataset_map = {\n    \"x_train\": DataConnector.from_dataframe(X_train),\n    \"y_train\": DataConnector.from_dataframe(y_train),\n    \"x_test\": DataConnector.from_dataframe(X_test),\n    \"y_test\": DataConnector.from_dataframe(y_test)\n    }\n\n\n# Define a training function, with any models you choose within it.\ndef train_func():\n    # A context object provided by HPO API to expose data for the current HPO trial\n    tuner_context = get_tuner_context()\n    config = tuner_context.get_hyper_params()\n    dm = tuner_context.get_dataset_map()\n\n    ohe = OneHotEncoder(sparse_output=False).set_output(transform=\"pandas\")\n    impute = SimpleImputer(strategy='constant',fill_value=0).set_output(transform=\"pandas\")\n\n    transformer = ColumnTransformer(\n        [\n            ('ohe', ohe, X_train_pd.select_dtypes(\"object\").columns),\n            ('impute', impute, X_train_pd.select_dtypes(\"number\").columns)\n        ],\n        remainder='passthrough',\n        verbose_feature_names_out=False\n    ).set_output(transform='pandas')\n\n    \n    xgb = XGBClassifier(**config, random_state=42)\n\n    model = Pipeline(\n    [\n        ('transform', transformer),\n        ('xgb', xgb)\n    ]\n)\n    model.fit(dm[\"x_train\"].to_pandas().sort_index(), dm[\"y_train\"].to_pandas().sort_index())\n    f1_metric = f1_score(\n        dm[\"y_train\"].to_pandas().sort_index(), model.predict(dm[\"x_train\"].to_pandas().sort_index())\n    )\n    tuner_context.report(metrics={\"f1_score\": f1_metric}, model=model)\n\ntuner = tune.Tuner(\n    train_func=train_func,\n    search_space={\n        \"max_depth\": tune.randint(1, 10),\n        \"learning_rate\": tune.uniform(0.01, 0.1),\n        \"n_estimators\": tune.randint(50, 100),\n    },\n    tuner_config=tune.TunerConfig(\n        metric=\"f1_score\",\n        mode=\"max\",\n        search_alg=search_algorithm.RandomSearch(random_state=101),\n        num_trials=8, #run 8 trial runs\n        max_concurrent_trials=psutil.cpu_count(logical=False) # Use all available CPUs to run distributed HPO across. GPUs can also be used here! \n    ),\n)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b4abec2b-308a-42a6-b2b2-3439b12c88e9",
   "metadata": {
    "language": "python",
    "name": "run_hpo",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "#Train several model candidates (note this may take 1-2 minutes)\ntuner_results = tuner.run(dataset_map=dataset_map)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9ee37c42-3de7-476a-b7c0-d56952dac385",
   "metadata": {
    "language": "python",
    "name": "inspect_hpo_params",
    "codeCollapsed": false,
    "collapsed": false
   },
   "outputs": [],
   "source": "#Select best model results and inspect configuration\ntuned_model = tuner_results.best_model\ntuned_model",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "94b4a6c2-674e-4d02-afdb-8ebf10cffdc4",
   "metadata": {
    "language": "python",
    "name": "compute_hpo_train_predictions_and_metrics",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "#Generate predictions\nxgb_opt_preds = tuned_model.predict(train_pd.drop([\"TIMESTAMP\", \"LOAN_ID\", \"MORTGAGERESPONSE\"],axis=1))\n\n#Generate performance metrics\nf1_opt_train = round(f1_score(train_pd.MORTGAGERESPONSE, xgb_opt_preds),4)\nprecision_opt_train = round(precision_score(train_pd.MORTGAGERESPONSE, xgb_opt_preds),4)\nrecall_opt_train = round(recall_score(train_pd.MORTGAGERESPONSE, xgb_opt_preds),4)\n\nprint(f'Train Results: \\nF1: {f1_opt_train} \\nPrecision {precision_opt_train} \\nRecall: {recall_opt_train}')",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dee80c48-d521-4b77-8841-54ba35ecd4b6",
   "metadata": {
    "language": "python",
    "name": "compute_hpo_test_predictions_and_metrics",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "#Generate test predictions\nxgb_opt_preds_test = tuned_model.predict(test_pd.drop([\"TIMESTAMP\", \"LOAN_ID\", \"MORTGAGERESPONSE\"],axis=1))\n\n#Generate performance metrics on test data\nf1_opt_test = round(f1_score(test_pd.MORTGAGERESPONSE, xgb_opt_preds_test),4)\nprecision_opt_test = round(precision_score(test_pd.MORTGAGERESPONSE, xgb_opt_preds_test),4)\nrecall_opt_test = round(recall_score(test_pd.MORTGAGERESPONSE, xgb_opt_preds_test),4)\n\nprint(f'Test Results: \\nF1: {f1_opt_test} \\nPrecision {precision_opt_test} \\nRecall: {recall_opt_test}')",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "89a1a670-52e3-4d77-ac3a-db830e22fdcf",
   "metadata": {
    "name": "HPO_performance_reaction",
    "collapsed": false
   },
   "source": "# Here we see the HPO model has a more modest train accuracy than our base model - but the peformance doesn't drop off during testing"
  },
  {
   "cell_type": "code",
   "id": "d501cf7d-4965-4b9f-8b16-edab897d0e18",
   "metadata": {
    "language": "python",
    "name": "log_hpo_model",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "#Log the optimized model to the model registry (if not already there)\noptimized_version_name = version_model(tuned_model)\n\ntry:\n    #Check for existing model\n    mv_opt = model_registry.get_model(model_name).version(optimized_version_name)\n    print(\"Found existing model version!\")\nexcept:\n    #Log model to registry\n    print(\"Logging new model version...\")\n    mv_opt = model_registry.log_model(\n        model_name=model_name,\n        model=tuned_model, \n        version_name=optimized_version_name,\n        sample_input_data = train.drop([\"TIMESTAMP\", \"LOAN_ID\", \"MORTGAGERESPONSE\"]).limit(100),\n        comment = f\"\"\"HPO ML model for predicting loan approval likelihood.\n            This model was trained using XGBoost classifier.\n            Optimized hyperparameters used were:\n            max_depth={tuned_model.named_steps['xgb'].max_depth}, \n            n_estimators={tuned_model.named_steps['xgb'].n_estimators}, \n            learning_rate = {tuned_model.named_steps['xgb'].learning_rate}, \n            \"\"\",\n        target_platforms= [\"WAREHOUSE\", \"SNOWPARK_CONTAINER_SERVICES\"],\n        options= {\"enable_explainability\": False}\n\n        \n\n    )\n    #Set metrics\n    mv_opt.set_metric(metric_name=\"Train_F1_Score\", value=f1_opt_train)\n    mv_opt.set_metric(metric_name=\"Train_Precision_Score\", value=precision_opt_train)\n    mv_opt.set_metric(metric_name=\"Train_Recall_score\", value=recall_opt_train)\n\n    mv_opt.set_metric(metric_name=\"Test_F1_Score\", value=f1_opt_test)\n    mv_opt.set_metric(metric_name=\"Test_Precision_Score\", value=precision_opt_test)\n    mv_opt.set_metric(metric_name=\"Test_Recall_score\", value=recall_opt_test)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c4c028b9-b590-45b4-9884-35ee206bca0d",
   "metadata": {
    "language": "python",
    "name": "inspect_current_default_version",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "#Here we see the BASE version is our default version\nmodel_registry.get_model(model_name).default",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "04ac97a9-7af4-4331-bb0d-cf6ecc4a77f6",
   "metadata": {
    "language": "python",
    "name": "promote_optimized_version_to_default",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "#Now we'll set the optimized model to be the default model version going forward\nmodel_registry.get_model(model_name).default = optimized_version_name",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c04efcee-27e6-4423-b669-849bec7cc8fb",
   "metadata": {
    "language": "python",
    "name": "see_updated_model_versions",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "#Now we see our optimized version we have now recently promoted to our DEFAULT model version\nmodel_registry.get_model(model_name).default",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8cc92f7f-5f02-4cc5-82d0-758f65f2d485",
   "metadata": {
    "language": "python",
    "name": "update_model_tags",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "#we'll now update the PROD tagged model to be the optimized model version rather than our overfit base version\nm.unset_tag(\"PROD\")\nm.set_tag(\"PROD\", optimized_version_name)\nm.show_tags()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "05fff15e-5f49-4d4f-a02a-93e8f3114b11",
   "metadata": {
    "name": "explainability_MD",
    "collapsed": false
   },
   "source": "## Now that we've deployed some model versions and tested inference... \n# Let's explain our models!\n- ### Snowflake offers built in explainability capabilities on top of models logged to the model registry\n- ### In the below section we'll generate shapley values using these built in functions to understand how input features impact our model's behavior"
  },
  {
   "cell_type": "code",
   "id": "914f5cd6-d254-42d4-a0be-9848c9d09d4a",
   "metadata": {
    "language": "python",
    "name": "compute_shap_vals",
    "resultHeight": 0,
    "collapsed": false
   },
   "outputs": [],
   "source": "#create a sample of 1000 records\ntest_pd_sample=test_pd.sample(n=2500, random_state = 100).reset_index(drop=True)\n\n#Compute shapley values for each model\nbase_shap_pd = mv_base.run(test_pd_sample, function_name=\"explain\")\nopt_shap_pd = mv_opt.run(test_pd_sample, function_name=\"explain\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f606c231-2e6a-44ec-a17c-88bb5a3b6494",
   "metadata": {
    "language": "python",
    "name": "builtin_visualizations",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "from snowflake.ml.monitoring import explain_visualize\n\nfeat_df=test_pd_sample.drop([\"MORTGAGERESPONSE\",\"TIMESTAMP\", \"LOAN_ID\"],axis=1)\n\nexplain_visualize.plot_influence_sensitivity(base_shap_pd, feat_df, figsize=(1500, 500))\n\n#Optionally test out other built-in functionality \n# explain_visualize.plot_force(base_shap_pd.iloc[0], feat_df.iloc[0], figsize=(1500, 500))\n# explain_visualize.plot_violin(base_shap_pd, feat_df, figsize=(1400, 100))",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7d7cfb33-1062-487d-83bc-e3d32835e0d9",
   "metadata": {
    "name": "shap_viz",
    "collapsed": false
   },
   "source": "### In addition to built-in visualization capabilities you can always use open source packages like shap for additional visualizations"
  },
  {
   "cell_type": "code",
   "id": "f74e0dcc-a850-474a-b475-f05a77619731",
   "metadata": {
    "language": "python",
    "name": "base_shap_summary_plot",
    "resultHeight": 571,
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "import shap \n\nshap.summary_plot(np.array(base_shap_pd.astype(float)), \n                  test_pd_sample.drop([\"LOAN_ID\",\"MORTGAGERESPONSE\", \"TIMESTAMP\"], axis=1), \n                  feature_names = test_pd_sample.drop([\"LOAN_ID\",\"MORTGAGERESPONSE\", \"TIMESTAMP\"], axis=1).columns)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "67469a84-3d44-49e4-8d6e-5cd8a6e8a633",
   "metadata": {
    "language": "python",
    "name": "opt_shap_summary_plot",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "shap.summary_plot(np.array(opt_shap_pd.astype(float)), \n                  test_pd_sample.drop([\"LOAN_ID\",\"MORTGAGERESPONSE\", \"TIMESTAMP\"], axis=1), \n                  feature_names = test_pd_sample.drop([\"LOAN_ID\",\"MORTGAGERESPONSE\", \"TIMESTAMP\"], axis=1).columns)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f3a0d4c3-750c-4ae0-9812-85b677db6986",
   "metadata": {
    "language": "python",
    "name": "create_all_shap_dfs",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "\n#Merge shap vals and actual vals together for easier plotting below\nall_shap_base = test_pd_sample.merge(base_shap_pd, right_index=True, left_index=True, how='outer')\nall_shap_opt = test_pd_sample.merge(opt_shap_pd, right_index=True, left_index=True, how='outer')",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "938441fd-9ae3-4f97-9a54-b7e4c74738ac",
   "metadata": {
    "language": "python",
    "name": "plot_income_explanation",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "import seaborn as sns\nimport matplotlib.pyplot as plt\n\n#filter data down to strip outliers\nasb_filtered = all_shap_base[(all_shap_base.INCOME>0) & (all_shap_base.INCOME<250000)]\naso_filtered = all_shap_opt[(all_shap_opt.INCOME>0) & (all_shap_opt.INCOME<250000)]\n\n# Set up the figure\nfig, axes = plt.subplots(1, 2, figsize=(10, 6))\nfig.suptitle(\"INCOME EXPLANATION\")\n# Plot side-by-side boxplots\nsns.scatterplot(data = asb_filtered, x ='INCOME', y = 'INCOME_explanation', ax=axes[0])\nsns.regplot(data = asb_filtered, x =\"INCOME\", y = 'INCOME_explanation', scatter=False, color='red', line_kws={\"lw\":2},ci =100, lowess=False, ax =axes[0])\n\naxes[0].set_title('Base Model')\nsns.scatterplot(data = aso_filtered, x ='INCOME', y = 'INCOME_explanation',color = \"orange\", ax = axes[1])\nsns.regplot(data = aso_filtered, x =\"INCOME\", y = 'INCOME_explanation', scatter=False, color='blue', line_kws={\"lw\":2},ci =100, lowess=False, ax =axes[1])\naxes[1].set_title('Opt Model')\n\n# Customize and show the plot\nfor ax in axes:\n    ax.set_xlabel(\"Income\")\n    ax.set_ylabel(\"Influence\")\nplt.tight_layout()\nplt.show()\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2298b1f8-0495-42e1-b668-0dcd03d8bb7c",
   "metadata": {
    "language": "python",
    "name": "plot_loan_amount_explanation",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "#filter data down to strip outliers\nasb_filtered = all_shap_base[all_shap_base.LOAN_AMOUNT<2000000]\naso_filtered = all_shap_opt[all_shap_opt.LOAN_AMOUNT<2000000]\n\n\n# Set up the figure\nfig, axes = plt.subplots(1, 2, figsize=(10, 6))\nfig.suptitle(\"LOAN_AMOUNT EXPLANATION\")\n# Plot side-by-side boxplots\nsns.scatterplot(data = asb_filtered, x ='LOAN_AMOUNT', y = 'LOAN_AMOUNT_explanation', ax=axes[0])\nsns.regplot(data = asb_filtered, x =\"LOAN_AMOUNT\", y = 'LOAN_AMOUNT_explanation', scatter=False, color='red', line_kws={\"lw\":2},ci =100, lowess=True, ax =axes[0])\naxes[0].set_title('Base Model')\n\nsns.scatterplot(data = aso_filtered, x ='LOAN_AMOUNT', y = 'LOAN_AMOUNT_explanation',color = \"orange\", ax = axes[1])\nsns.regplot(data = aso_filtered, x =\"LOAN_AMOUNT\", y = 'LOAN_AMOUNT_explanation', scatter=False, color='blue', line_kws={\"lw\":2},ci =100, lowess=True, ax =axes[1])\naxes[1].set_title('Opt Model')\n\n# Customize and show the plot\nfor ax in axes:\n    ax.set_xlabel(\"LOAN_AMOUNT\")\n    ax.set_ylabel(\"Influence\")\n    # ax.set_xlim((0,10000))\nplt.tight_layout()\nplt.show()\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "14a03aa9-1f1a-4a4e-809e-b22e438d72aa",
   "metadata": {
    "language": "python",
    "name": "plot_home_purchase_explanation",
    "resultHeight": 851,
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Set up the figure\nfig, axes = plt.subplots(1, 2, figsize=(10, 6))\nfig.suptitle(\"HOME PURCHASE LOAN EXPLANATION\")\n# Plot side-by-side boxplots\nsns.boxplot(data = all_shap_base, x ='LOAN_PURPOSE_NAME_HOME_PURCHASE', y = 'LOAN_PURPOSE_NAME_HOME_PURCHASE_explanation',\n            hue='LOAN_PURPOSE_NAME_HOME_PURCHASE', width=0.8, ax=axes[0])\naxes[0].set_title('Base Model')\nsns.boxplot(data = all_shap_opt, x ='LOAN_PURPOSE_NAME_HOME_PURCHASE', y = 'LOAN_PURPOSE_NAME_HOME_PURCHASE_explanation',\n            hue='LOAN_PURPOSE_NAME_HOME_PURCHASE', width=0.4, ax = axes[1])\naxes[1].set_title('Opt Model')\n\n# Customize and show the plot\nfor ax in axes:\n    ax.set_xlabel(\"Home PURCHASE Loan (1 = True)\")\n    ax.set_ylabel(\"Influence\")\n    ax.legend(loc='upper right')\n\nplt.show()\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "66ea7aad-4e48-4666-a48c-ddc39331cb1f",
   "metadata": {
    "language": "python",
    "name": "plot_home_imrprovement_explanation",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Set up the figure\nfig, axes = plt.subplots(1, 2, figsize=(10, 6))\nfig.suptitle(\"HOME IMPROVEMENT LOAN EXPLANATION\")\n# Plot side-by-side boxplots\nsns.boxplot(data = all_shap_base, x ='LOAN_PURPOSE_NAME_HOME_IMPROVEMENT', y = 'LOAN_PURPOSE_NAME_HOME_IMPROVEMENT_explanation',\n            hue='LOAN_PURPOSE_NAME_HOME_IMPROVEMENT', width=0.8, ax=axes[0])\naxes[0].set_title('Base Model')\nsns.boxplot(data = all_shap_opt, x ='LOAN_PURPOSE_NAME_HOME_IMPROVEMENT', y = 'LOAN_PURPOSE_NAME_HOME_IMPROVEMENT_explanation',\n            hue='LOAN_PURPOSE_NAME_HOME_IMPROVEMENT', width=0.4, ax = axes[1])\naxes[1].set_title('Opt Model')\n\n# Customize and show the plot\nfor ax in axes:\n    ax.set_xlabel(\"Home Improvement Loan (1 = True)\")\n    ax.set_ylabel(\"Influence\")\n    ax.legend(loc='upper right')\n\nplt.show()\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "df7a9ccc-e785-4a82-b9e9-97fd44d5acf2",
   "metadata": {
    "name": "Monitoring_section",
    "collapsed": false,
    "resultHeight": 74
   },
   "source": "# Model Monitoring setup"
  },
  {
   "cell_type": "code",
   "id": "e0751bdd-6c24-4c65-9247-aa90ebc1d376",
   "metadata": {
    "language": "python",
    "name": "create_table_from_test_data",
    "resultHeight": 0,
    "collapsed": false
   },
   "outputs": [],
   "source": "train.write.save_as_table(f\"DEMO_MORTGAGE_LENDING_TRAIN_{fv_version}\", mode=\"overwrite\")\ntest.write.save_as_table(f\"DEMO_MORTGAGE_LENDING_TEST_{fv_version}\", mode=\"overwrite\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "aabdf2be-87f8-4556-aa42-22e4a70515e1",
   "metadata": {
    "language": "python",
    "name": "create_stage",
    "resultHeight": 111,
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "session.sql(\"CREATE stage IF NOT EXISTS ML_STAGE\").collect()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "21b2c090-5cc8-4847-982a-fb9b5e427616",
   "metadata": {
    "language": "python",
    "name": "define_sproc",
    "collapsed": false,
    "resultHeight": 495,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "from snowflake import snowpark\n\ndef demo_inference_sproc(session: snowpark.Session, table_name: str, modelname: str, modelversion: str) -> str:\n\n    reg = Registry(session=session)\n    m = reg.get_model(model_name)  # Fetch the model using the registry\n    mv = m.version(modelversion)\n    \n    input_table_name=table_name\n    pred_col = f'{modelversion}_PREDICTION'\n\n    # Read the input table to a dataframe\n    df = session.table(input_table_name)\n    results = mv.run(df, function_name=\"predict\").select(\"LOAN_ID\",'\"output_feature_0\"').withColumnRenamed('\"output_feature_0\"', pred_col)\n    # 'results' is the output DataFrame with predictions\n\n    final = df.join(results, on=\"LOAN_ID\", how=\"full\")\n    # Write results back to Snowflake table\n    final.write.save_as_table(table_name, mode='overwrite',enable_schema_evolution=True)\n\n    return \"Success\"\n\n# Register the stored procedure\nsession.sproc.register(\n    func=demo_inference_sproc,\n    name=\"model_inference_sproc\",\n    replace=True,\n    is_permanent=True,\n    stage_location=\"@ML_STAGE\",\n    packages=['joblib', 'snowflake-snowpark-python', 'snowflake-ml-python'],\n    return_type=StringType()\n)\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "da45031a-917e-4f6d-a2e4-068879791819",
   "metadata": {
    "language": "sql",
    "name": "gb_base_train_inference",
    "resultHeight": 111,
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "CALL model_inference_sproc('DEMO_MORTGAGE_LENDING_TRAIN_{{fv_version}}','{{model_name}}', '{{base_version_name}}');",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0d18ea05-7d29-43a3-9baa-52509f3bb15e",
   "metadata": {
    "language": "sql",
    "name": "gb_base_test_inference",
    "collapsed": false,
    "resultHeight": 111,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "CALL model_inference_sproc('DEMO_MORTGAGE_LENDING_TEST_{{fv_version}}','{{model_name}}', '{{base_version_name}}');",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c1d2550b-46c7-4eb7-adaa-64c345711b1e",
   "metadata": {
    "language": "sql",
    "name": "gb_opt_train_inference",
    "collapsed": false,
    "resultHeight": 111,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "CALL model_inference_sproc('DEMO_MORTGAGE_LENDING_TRAIN_{{fv_version}}','{{model_name}}', '{{optimized_version_name}}');",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8245f482-19e9-4961-9cb2-801bf5948d52",
   "metadata": {
    "language": "sql",
    "name": "gb_opt_test_inference",
    "collapsed": false,
    "resultHeight": 111,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "CALL model_inference_sproc('DEMO_MORTGAGE_LENDING_TEST_{{fv_version}}','{{model_name}}', '{{optimized_version_name}}');",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ec05048c-a9d1-4ef9-bf39-5333f3fb56cb",
   "metadata": {
    "language": "sql",
    "name": "see_preds",
    "resultHeight": 251,
    "codeCollapsed": false,
    "collapsed": false
   },
   "outputs": [],
   "source": "select \n    TIMESTAMP, \n    LOAN_ID, \n    INCOME, \n    LOAN_AMOUNT, \n    {{base_version_name}}_PREDICTION AS XGB_BASE_PREDICTION,\n    {{optimized_version_name}}_PREDICTION AS XGB_OPTIMIZED_PREDICTION,\n    MORTGAGERESPONSE \nFROM DEMO_MORTGAGE_LENDING_TEST_{{fv_version}} \nlimit 20",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2f6be548-47cb-4a91-92ee-a5f42c41e756",
   "metadata": {
    "language": "sql",
    "name": "create_model_monitor_base",
    "resultHeight": 111,
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "CREATE OR REPLACE MODEL MONITOR MORTGAGE_LENDING_BASE_MODEL_MONITOR\nWITH\n    MODEL={{model_name}}\n    VERSION={{base_version_name}}\n    FUNCTION=predict\n    SOURCE=DEMO_MORTGAGE_LENDING_TEST_{{fv_version}}\n    BASELINE=DEMO_MORTGAGE_LENDING_TRAIN_{{fv_version}}\n    TIMESTAMP_COLUMN=TIMESTAMP\n    PREDICTION_CLASS_COLUMNS=({{base_version_name}}_PREDICTION)  \n    ACTUAL_CLASS_COLUMNS=(MORTGAGERESPONSE)\n    ID_COLUMNS=(LOAN_ID)\n    WAREHOUSE={{COMPUTE_WAREHOUSE}}\n    REFRESH_INTERVAL='1 hour'\n    AGGREGATION_WINDOW='1 day';",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "60965976-f17f-42bc-92ae-e43030bba54e",
   "metadata": {
    "language": "sql",
    "name": "create_model_monitor_optimized",
    "resultHeight": 111,
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "CREATE OR REPLACE MODEL MONITOR MORTGAGE_LENDING_OPTIMIZED_MODEL_MONITOR\nWITH\n    MODEL={{model_name}}\n    VERSION={{optimized_version_name}}\n    FUNCTION=predict\n    SOURCE=DEMO_MORTGAGE_LENDING_TEST_{{fv_version}}\n    BASELINE=DEMO_MORTGAGE_LENDING_TRAIN_{{fv_version}}\n    TIMESTAMP_COLUMN=TIMESTAMP\n    PREDICTION_CLASS_COLUMNS=({{optimized_version_name}}_PREDICTION)  \n    ACTUAL_CLASS_COLUMNS=(MORTGAGERESPONSE)\n    ID_COLUMNS=(LOAN_ID)\n    WAREHOUSE={{COMPUTE_WAREHOUSE}}\n    REFRESH_INTERVAL='12 hours'\n    AGGREGATION_WINDOW='1 day';",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b78b0fc2-555d-458b-aa07-7053859539d4",
   "metadata": {
    "language": "python",
    "name": "generate_model_registry_link",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "#Click the generated link to view your model in the model regsitry and check out the model monitors!\nst.write(f'https://app.snowflake.com/{org_name}/{account_name}/#/data/databases/{DB}/schemas/{SCHEMA}/model/{model_name.upper()}')",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "537fc658-38f4-4c9a-980b-cf40ef61a268",
   "metadata": {
    "language": "sql",
    "name": "compute_prediction_drift",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "SELECT * FROM TABLE(MODEL_MONITOR_DRIFT_METRIC(\n'MORTGAGE_LENDING_BASE_MODEL_MONITOR', -- model monitor to use\n'DIFFERENCE_OF_MEANS', -- metric for computing drift\n'{{optimized_version_name}}_PREDICTION', -- comlumn to compute drift on\n'1 DAY',  -- day granularity for drift computation\nDATEADD(DAY, -90, CURRENT_DATE()), -- end date\nDATEADD(DAY, -60, CURRENT_DATE()) -- start date\n)\n)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7b8f8d88-1ebe-4622-89ca-39bce08473d4",
   "metadata": {
    "name": "SPCS_MD",
    "collapsed": false
   },
   "source": "# SPCS Deployment setup (OPTIONAL)\n## This is disabled by default but uncommenting the below code cells will allow a user to \n\n- ### Create a new compute pool with 3 XL CPU nodes\n- ### Deploys a service on top of our existing HPO model version\n- ### Tests out inference on newly created container service\n"
  },
  {
   "cell_type": "code",
   "id": "c416a4d0-a95f-4702-9a61-26b61706eb11",
   "metadata": {
    "language": "python",
    "name": "define_spcs_vars",
    "collapsed": false
   },
   "outputs": [],
   "source": "# cp_name = \"MORTGAGE_LENDING_INFERENCE_CP\"\n# num_spcs_nodes = '3'\n# spcs_instance_family = 'CPU_X64_L'\n# service_name = 'MORTGAGE_LENDING_PREDICTION_SERVICE'\n\n# current_database = session.get_current_database().replace('\"', '')\n# current_schema = session.get_current_schema().replace('\"', '')\n# extended_service_name = f'{current_database}.{current_schema}.{service_name}'",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "448f6702-8fb2-4aac-9e54-a8673c064074",
   "metadata": {
    "language": "python",
    "name": "setup_compute_pool",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# session.sql(f\"alter compute pool if exists {cp_name} stop all\").collect()\n# session.sql(f\"drop compute pool if exists {cp_name}\").collect()\n# session.sql(f\"create compute pool {cp_name} min_nodes={num_spcs_nodes} max_nodes={num_spcs_nodes} instance_family={spcs_instance_family} auto_resume=True auto_suspend_secs=300\").collect()\n# session.sql(f\"describe compute pool {cp_name}\").show()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "df47725b-e9e7-4f93-bdea-9db09794bd95",
   "metadata": {
    "language": "python",
    "name": "spcs_deploy_service",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# note this may take up to 5 minutes to run\n\n# mv_opt.create_service(\n#     service_name=extended_service_name,\n#     service_compute_pool=cp_name,\n#     ingress_enabled=True,\n#     max_instances=int(num_spcs_nodes)\n# )",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "25c4f6d4-b16b-4448-bcf3-4f128ccfbe43",
   "metadata": {
    "language": "python",
    "name": "see_model_versions_with_services",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# model_registry.get_model(f\"MORTGAGE_LENDING_MLOPS\").show_versions()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3f6dcb97-aa8f-467b-a939-63d1d3b70f58",
   "metadata": {
    "language": "python",
    "name": "view_services",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# mv_container = model_registry.get_model(f\"MORTGAGE_LENDING_MLOPS\").default\n# mv_container.list_services()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c5eb9b1a-0741-4e9d-aaf4-2da26c44ffbd",
   "metadata": {
    "language": "python",
    "name": "run_SPCS_inference",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# mv_container.run(test, function_name = \"predict\", service_name = \"MORTGAGE_LENDING_PREDICTION_SERVICE\").rename('\"output_feature_0\"', 'XGB_PREDICTION')",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "35388bca-f70f-47db-a3ef-3558dda91502",
   "metadata": {
    "language": "python",
    "name": "stop_compute_pool",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "#Stop the service to save costs\n# session.sql(f\"alter compute pool if exists {cp_name} stop all\").collect()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [],
    "name": "conclusion",
    "resultHeight": 202,
    "collapsed": false
   },
   "source": "## Conclusion \n\n#### 🛠️ Snowflake Feature Store tracks feature definitions and maintains lineage of sources and destinations 🛠️\n#### 🚀 Snowflake Model Registry gives users a secure and flexible framework to log models, tag candidates for production, and run inference and explainability jobs 🚀\n#### 📈 ML observability in Snowflake allows users to montior model performance over time and detect model, feature, and concept drift 📈\n#### 🔮 All models logged in the Model Registry can be accessed for inference, explainability, lineage tracking, visibility and more 🔮\n",
   "id": "ce110000-1111-2222-3333-ffffff000036"
  }
 ]
}